{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ipl I317B Sécurité : labos\n",
    "## Semaine 1 : introduction et outils python\n",
    "\n",
    "### Partie 1 : manipuler du texte"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercice 1\n",
    "Pour ce premier exercice, nous allons manipuler un court extrait de logs d'un serveur web nginx.  \n",
    "Pour chaque ligne de celui-ci, extrayez:\n",
    "- l'adresse IP\n",
    "- le timestamp\n",
    "- le chemin demandé"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs = \"\"\"91.160.48.68 - - [3/Sep/2020:18:18:10 +0200] \"GET /?C=M;O=D HTTP/1.1\" 301 178 \"-\" \"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:80.0) Gecko/20100101 Firefox/80.0\" \"-\"\n",
    "78.224.72.158 - - [3/Sep/2020:18:24:52 +0200] \"GET / HTTP/1.1\" 301 178 \"-\" \"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:80.0) Gecko/20100101 Firefox/80.0\" \"-\"\n",
    "192.241.199.4 - - [3/Sep/2020:19:11:15 +0200] \"GET / HTTP/1.1\" 301 178 \"-\" \"Mozilla/5.0 zgrab/0.x\" \"-\"\n",
    "40.121.69.161 - - [3/Sep/2020:19:16:32 +0200] \"GET /.env HTTP/1.1\" 301 178 \"-\" \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/81.0.4044.129 Safari/537.36\" \"-\"\n",
    "40.121.69.161 - - [3/Sep/2020:19:16:32 +0200] \"POST / HTTP/1.1\" 301 178 \"-\" \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/81.0.4044.129 Safari/537.36\" \"-\"\n",
    "185.172.110.223 - - [3/Sep/2020:19:16:37 +0200] \"GET / HTTP/1.1\" 301 178 \"-\" \"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:76.0) Gecko/20100101 Firefox/76.0\" \"-\"\n",
    "66.249.75.16 - - [3/Sep/2020:19:23:28 +0200] \"GET / HTTP/1.1\" 301 178 \"-\" \"Mozilla/5.0 (Linux; Android 6.0.1; Nexus 5X Build/MMB29P) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/85.0.4183.97 Mobile Safari/537.36 (compatible; Googlebot/2.1; +http://www.google.com/bot.html)\" \"-\"\n",
    "66.249.75.23 - - [3/Sep/2020:19:23:30 +0200] \"GET / HTTP/1.1\" 200 0 \"-\" \"Mozilla/5.0 (Linux; Android 6.0.1; Nexus 5X Build/MMB29P) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/85.0.4183.97 Mobile Safari/537.36 (compatible; Googlebot/2.1; +http://www.google.com/bot.html)\" \"-\" \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91.160.48.68\n",
      "3/Sep/2020:18:18:10 +0200\n",
      "/?C=M;O=D\n",
      "----\n",
      "78.224.72.158\n",
      "3/Sep/2020:18:24:52 +0200\n",
      "/\n",
      "----\n",
      "192.241.199.4\n",
      "3/Sep/2020:19:11:15 +0200\n",
      "/\n",
      "----\n",
      "40.121.69.161\n",
      "3/Sep/2020:19:16:32 +0200\n",
      "/.env\n",
      "----\n",
      "40.121.69.161\n",
      "3/Sep/2020:19:16:32 +0200\n",
      "/\n",
      "----\n",
      "185.172.110.223\n",
      "3/Sep/2020:19:16:37 +0200\n",
      "/\n",
      "----\n",
      "66.249.75.16\n",
      "3/Sep/2020:19:23:28 +0200\n",
      "/\n",
      "----\n",
      "66.249.75.23\n",
      "3/Sep/2020:19:23:30 +0200\n",
      "/\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "for line in logs.split(\"\\n\"):\n",
    "    print(line.split(\" - - \",1)[0])\n",
    "    print(line.split(\" - - \",1)[1][:27].strip(\"[]\"))\n",
    "    print(line.split(\" - - \",1)[1].split(\" \")[3])\n",
    "    print(\"----\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercice 2\n",
    "Avec les mêmes logs que l'exercice précédent, comptez et affichez les différents user-agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Different user agent:  5\n",
      "---------\n",
      "2 => Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:80.0) Gecko/20100101 Firefox/80.0\n",
      "1 => Mozilla/5.0 zgrab/0.x\n",
      "2 => Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/81.0.4044.129 Safari/537.36\n",
      "1 => Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:76.0) Gecko/20100101 Firefox/76.0\n",
      "2 => Mozilla/5.0 (Linux; Android 6.0.1; Nexus 5X Build/MMB29P) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/85.0.4183.97 Mobile Safari/537.36 (compatible; Googlebot/2.1; +http://www.google.com/bot.html)\n"
     ]
    }
   ],
   "source": [
    "logs_set = set()\n",
    "for line in logs.split(\"\\n\"):\n",
    "    #print(line.split('\"-\"')[1][2:-2])\n",
    "    logs_set.add(line.split('\"-\"')[1][2:-2])\n",
    "print(\"Different user agent: \", len(logs_set))\n",
    "\n",
    "#en comptant les occurences de chacun\n",
    "\n",
    "\n",
    "logs_map = {}\n",
    "\n",
    "for line in logs.split(\"\\n\"):\n",
    "    ua = line.split('\"-\"')[1][2:-2]\n",
    "    \n",
    "    if ua not in logs_map:\n",
    "        logs_map[ua] = 0\n",
    "    \n",
    "    logs_map[ua] += 1;\n",
    "\n",
    "print(\"---------\")\n",
    "for k, v in logs_map.items():\n",
    "    print(v, '=>', k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partie 2 : requests et BeautifulSoup\n",
    "\n",
    "Assurez vous que les paquets suivant soient bien installé :\n",
    "\n",
    "`pip3 install --user requests bs4`\n",
    "\n",
    "`sudo pip3 install requests bs4`\n",
    "\n",
    "Depuis un jupyter notebook, vous pouvez probablement juste executer la case suivante :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\programdata\\anaconda3\\lib\\site-packages (2.27.1)\n",
      "Requirement already satisfied: bs4 in c:\\users\\20201652\\appdata\\roaming\\python\\python39\\site-packages (0.0.1)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests) (3.3)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\programdata\\anaconda3\\lib\\site-packages (from bs4) (4.11.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from beautifulsoup4->bs4) (2.3.1)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install --user requests bs4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le packet requests nous permet de faire des requêtes web facilement, par exemple :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "ipl_req = requests.get(\"https://www.vinci.be/fr/formations/informatique-de-gestion\")\n",
    "\n",
    "if ipl_req.ok: # ipl_req.status_code == 200 c'est la meme chose\n",
    "    ipl_html = ipl_req.text\n",
    "    print(ipl_req.status_code)\n",
    "    \n",
    "else:\n",
    "    print(ipl_req.status_code)\n",
    "    print(ipl_req.reason)\n",
    "\n",
    "# Doc requests : https://requests.readthedocs.io/en/latest/ )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons ensuite lire le code source de la page en affichant `ipl_html`.\n",
    "\n",
    "Parser du html avec des split ou des regex deviendrait vite infernal, c'est là qu'intervient la librairie BeautifulSoup qui nous permet de parcourir beaucoup plus simplement le dom notamment avec les fonctions `find` et `find_all`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Informatique de gestion | HE VINCI\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "soup = BeautifulSoup(ipl_html)\n",
    "\n",
    "# pour récupérer le contenu de la balise <title> :\n",
    "title = soup.find(\"title\").get_text()\n",
    "\n",
    "print(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La fonction `find` et la fonction `find_all` vous renverons un object de type `tag` (balise) sur lequel vous pouvez faire :\n",
    "  * d'autres `find()` et `find_all()`\n",
    "  * `get_text()` pour récupérer tout le contenu textuel de la balise\n",
    "  * `[\"nom de l'attribut\"]` pour récupérer un attribut en particulier (exemple: `tag['href']`)\n",
    "  * ...\n",
    "\n",
    "( Doc BeautifulSoup4 : https://www.crummy.com/software/BeautifulSoup/bs4/doc/ )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercice 1:\n",
    "Récupérez le contenue de la page suivante et affichez son titre proprement : https://www.vinci.be/fr/formations/informatique-de-gestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Informatique de gestion | HE VINCI\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "ipl_req = requests.get(\"https://www.vinci.be/fr/formations/informatique-de-gestion\")\n",
    "\n",
    "soup = BeautifulSoup(ipl_html)\n",
    "\n",
    "# pour récupérer le contenu de la balise <title> :\n",
    "title = soup.find(\"title\").get_text()\n",
    "\n",
    "print(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il est possible de faire des requêtes beaucoup plus poussée en ajoutant des arguments correspondant aux attributs des balises que nous cherchons, par exemple pour trouver les balises `<div class=\"footer\"></div>` :\n",
    "\n",
    "```\n",
    "soup.find_all(\"div\", class_=\"footer\")\n",
    "# NB: class est un mot clé réservé en python, d'où l'ajout du \"_\" dans BeautifulSoup\n",
    "```\n",
    "\n",
    "Ou encore pour trouver tous les liens vers la page facebook de l'ipl :\n",
    "\n",
    "`soup.find_all(\"a\", href=\"https://www.facebook.com/HEVINCI\")`\n",
    "\n",
    "BeautifoulSoup accepte également des regex compilée en argument, il est donc possible de récupérer la liste des url qui ne sont pas du domaines de \"vinci.be\" :\n",
    "\n",
    "```\n",
    "import re\n",
    "\n",
    "not_vinci = re.compile(\"^http(s?)://(?!www.vinci.be/).*$\")\n",
    "soup.find_all(\"a\", href=not_vinci)\n",
    "```\n",
    "\n",
    "Il est également possible d'utiliser une fonction arbitraire pour valider les liens. Par exemple, pour trouver tous les liens de moins de 30 caractères :\n",
    "\n",
    "```\n",
    "def less_than_30(tag):\n",
    "    return len(tag) < 30  # on retourne un booleen\n",
    "    \n",
    "# on passe notre fonction en paramètre sans l'executer :\n",
    "soup.find_all(\"a\", href=less_than_30)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercice 2:\n",
    "\n",
    "Utilisez des regex pour récupérer la liste des liens http (et donc pas https) sur la page :  \n",
    "https://www.vinci.be/fr/formations/informatique-de-gestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipl_https = requests.get(\"https://www.vinci.be/fr/formations/informatique-de-gestion\")\n",
    "soup = BeautifulSoup(ipl_https.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercice 3:\n",
    "\n",
    "Utilisez une fonction pour récupérer tous les liens qui finissent avec une extension désignant un type de ficher (ex: \".html\", \".php\", \".pdf\", ...) sur la page :  \n",
    "https://www.vinci.be/fr/formations/informatique-de-gestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercice 4:\n",
    "Depuis le site du Centre Cybersecurité Belgique https://ccb.belgium.be/fr/actualit%C3%A9s , récupérez la liste des articles récents et affichez leurs titres ainsi qu'un lien vers l'article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "<h2 class=\"teaser-title\">10 talents belges ont participé à la compétition European Cybersecurity Challenge</h2>\n"
     ]
    }
   ],
   "source": [
    "req = requests.get(\"https://ccb.belgium.be/fr/actualit%C3%A9s\")\n",
    "soup = BeautifulSoup(req.text)\n",
    "\n",
    "print(req.status_code)\n",
    "\n",
    "for article in soup.find_all(\"article\"):\n",
    "    print(article.find('h2', class_ = \"teaser-title\"))\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercice 5:\n",
    "La lib requests permet également d'effectuer de requête POST. Pour tester cette fonctionnalitée, créez un \"requestbin\" sur le site http://requestbin.net/ puis utilisez requests pour poster des données vers votre requestbin.\n",
    "\n",
    "> RequestBin gives you a URL that will collect requests made to it and let you inspect them in a human-friendly way.\n",
    "Use RequestBin to see what your HTTP client is sending or to inspect and debug webhook requests.\n",
    "\n",
    "\n",
    "Voir : https://requests.readthedocs.io/en/master/user/quickstart/#make-a-request (ou la cheatsheet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercice 6:\n",
    "\n",
    "Maintenant que vous maîtrisez le get, le post et quelques bases de parsing web, \"connectez-vous\" au formulaire suivant avec les identifiants : `admin/admin`  \n",
    "http://labosecuipl.alwaysdata.net/21/s01/form/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercice 7:\n",
    "Vous avez certainement constaté sur votre requestbin que la librairie requests utilise par défaut un User-Agent explicite \"*je suis un lib python pour faire des requêtes*\".  \n",
    "Documentez-vous sur la manière de changer celui-ci dans requests et remplacez le dans votre précédente requête vers requestbin par quelque chose de plus discret, par exemple l'user-agent de la dernière version de chrome :  \n",
    "`Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/93.0.4577.63 Safari/537.36`\n",
    "\n",
    "source: https://www.whatismybrowser.com/guides/the-latest-user-agent/chrome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partie 3 (bonus):\n",
    "\n",
    "Note: dans les jupyter notebook, vous pouvez exécuter des commandes shell en préfixant une cellule d'un `!`. Par exemple : `!date`.\n",
    "\n",
    "Exercice 1\n",
    "\n",
    "Pour ce premier exercice, nous allons manipuler un court extrait de logs \"logs.txt\" d'un serveur web nginx (le même que pour la partie 1).\n",
    "\n",
    "Pour chaque ligne de celui-ci, extrayez:\n",
    "\n",
    "    l'adresse IP\n",
    "    le timestamp\n",
    "    le chemin demandé\n",
    "\n",
    "En n'utilisant que des commandes bash : cat, grep, cut, sort, uniq,..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Sep 20 05:21:27 AM UTC 2022\n"
     ]
    }
   ],
   "source": [
    "!date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TODO\n"
     ]
    }
   ],
   "source": [
    "!echo \"TODO\" | grep \"DO\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercice 2\n",
    "Avec les mêmes logs que l'exercice précédent, comptez et affichez les différents user-agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TODO\n"
     ]
    }
   ],
   "source": [
    "!echo \"TODO\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
